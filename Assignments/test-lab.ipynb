{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4ee6c6e36c44098ab724097dc3559b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, description='Alpha:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Generate sample data for two layers\n",
    "layer1 = np.random.rand(10, 10)\n",
    "layer2 = np.random.rand(10, 10)\n",
    "\n",
    "def update_layers(alpha):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(layer1, cmap='Blues', interpolation='none')\n",
    "    ax.imshow(layer2, cmap='Reds', interpolation='none', alpha=alpha)\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for alpha blending\n",
    "alpha_slider = widgets.FloatSlider(value=0.5, min=0, max=1, step=0.01, description='Alpha:')\n",
    "widgets.interactive(update_layers, alpha=alpha_slider)\n",
    "\n",
    "# Display the slider\n",
    "display(alpha_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c840f68b82d447a39e31a818d9584ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, description='Alpha:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Generate sample images for the DataFrame\n",
    "image1 = np.random.rand(10, 10)\n",
    "image2 = np.random.rand(10, 10)\n",
    "\n",
    "# Create a DataFrame to store the images\n",
    "df = pd.DataFrame({\n",
    "    'Image1': [image1],\n",
    "    'Image2': [image2]\n",
    "})\n",
    "\n",
    "def update_overlay(alpha):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(df['Image1'][0], cmap='Blues', interpolation='none')\n",
    "    ax.imshow(df['Image2'][0], cmap='Reds', interpolation='none', alpha=alpha)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Create a slider widget for alpha blending\n",
    "alpha_slider = widgets.FloatSlider(value=0.5, min=0, max=1, step=0.01, description='Alpha:')\n",
    "widgets.interactive(update_overlay, alpha=alpha_slider)\n",
    "\n",
    "# Display the slider\n",
    "display(alpha_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881c5eaf0124496baea3b60f24a46386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.5, description='Alpha:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Generate sample images for the DataFrame\n",
    "image1 = np.random.rand(10, 10)\n",
    "image2 = np.random.rand(10, 10)\n",
    "\n",
    "# Create a DataFrame to store the images\n",
    "df = pd.DataFrame({\n",
    "    'Image1': [image1],\n",
    "    'Image2': [image2]\n",
    "})\n",
    "\n",
    "def update_overlay(alpha):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(df['Image1'][0], cmap='Blues', interpolation='none')\n",
    "    ax.imshow(df['Image2'][0], cmap='Reds', interpolation='none', alpha=alpha)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for alpha blending\n",
    "alpha_slider = widgets.FloatSlider(value=0.5, min=0, max=1, step=0.01, description='Alpha:')\n",
    "widgets.interactive(update_overlay, alpha=alpha_slider)\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "display(alpha_slider)\n",
    "update_overlay(alpha_slider.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.79341203 0.12633878 0.74266006 0.83377559 0.3624917  0.20732528\n",
      "  0.62719394 0.94991688 0.69079523 0.05034275]\n",
      " [0.94674935 0.20010789 0.7343991  0.31485664 0.08902951 0.8182286\n",
      "  0.25092349 0.90860507 0.01921333 0.4961848 ]\n",
      " [0.21073731 0.86453002 0.76951748 0.53241386 0.15556296 0.16535313\n",
      "  0.69424645 0.29492863 0.6052187  0.18146717]\n",
      " [0.72090062 0.24248392 0.4388084  0.94986762 0.23327385 0.66328238\n",
      "  0.47666385 0.13299748 0.74059519 0.02424384]\n",
      " [0.99314871 0.21393485 0.96540502 0.3367715  0.9688553  0.55162416\n",
      "  0.8066799  0.68288374 0.52845155 0.8496307 ]\n",
      " [0.80440147 0.54156336 0.23070722 0.4783763  0.19595754 0.29644928\n",
      "  0.61472045 0.38752444 0.95707737 0.77550531]\n",
      " [0.57304054 0.8848433  0.85489589 0.90786428 0.6431956  0.00361303\n",
      "  0.61630574 0.06876809 0.46929063 0.85206817]\n",
      " [0.24770351 0.87803068 0.74483384 0.04374388 0.89167152 0.18630937\n",
      "  0.42351176 0.44042137 0.67988675 0.05893956]\n",
      " [0.09238787 0.40218173 0.2596747  0.41084408 0.30953391 0.08293067\n",
      "  0.45981858 0.02376084 0.41699465 0.155644  ]\n",
      " [0.9650676  0.47847258 0.80392554 0.49557975 0.73487597 0.10512796\n",
      "  0.95982688 0.71418537 0.08250232 0.35273117]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d12f24f913e4214aaafb993fcddebb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Scroll:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Generate sample images for the DataFrame\n",
    "image1 = np.random.rand(10, 10)  # Base image\n",
    "image2 = np.random.rand(10, 10)  # Overlay image\n",
    "print(df['Image1'][0])\n",
    "\n",
    "# Create a DataFrame to store the images\n",
    "df = pd.DataFrame({\n",
    "    'Image1': [image1],\n",
    "    'Image2': [image2]\n",
    "})\n",
    "\n",
    "def update_overlay(scroll):\n",
    "    fig, ax = plt.subplots()\n",
    "    width = df['Image1'][0].shape[1]\n",
    "    scroll_position = int(width * scroll)\n",
    "\n",
    "    # Create the overlay image with scrolling\n",
    "    combined_image = df['Image1'][0].copy()\n",
    "    combined_image[:, scroll_position:] = df['Image2'][0][:, scroll_position:]\n",
    "    \n",
    "    ax.imshow(combined_image, cmap='gray', interpolation='none')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for scrolling\n",
    "scroll_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.01, description='Scroll:')\n",
    "widgets.interactive(update_overlay, scroll=scroll_slider)\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "display(scroll_slider)\n",
    "update_overlay(scroll_slider.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243de21ab84e447ea6f4e8f29cc428ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Scroll:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9a08ae254a4825ad91d0e37914bc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Generate sample images for the DataFrame\n",
    "image1 = np.random.rand(100, 100)  # Base image\n",
    "image2 = np.random.rand(100, 100)  # Overlay image\n",
    "\n",
    "# Create a DataFrame to store the images\n",
    "df = pd.DataFrame({\n",
    "    'Image1': [image1],\n",
    "    'Image2': [image2]\n",
    "})\n",
    "\n",
    "def update_overlay1(x_pos):\n",
    "    fig, ax = plt.subplots()\n",
    "    # Display the base image\n",
    "    ax.imshow(df['Image1'][0], cmap='gray', interpolation='none')\n",
    "    \n",
    "    # Create an overlay with the right part transparent\n",
    "    overlay = np.copy(df['Image2'][0])\n",
    "    overlay[:, :x_pos] = df['Image1'][0][:, :x_pos]  # Use base image for the left part\n",
    "\n",
    "    # Display the overlay image with transparency\n",
    "    ax.imshow(overlay, cmap='Reds', interpolation='none', alpha=0.5)\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for horizontal scrolling\n",
    "#x_slider = widgets.IntSlider(value=50, min=0, max=100, step=1, description='Scroll:')\n",
    "#widgets.interactive(update_overlay, x_pos=x_slider)\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "#display(x_slider)\n",
    "#update_overlay(10)\n",
    "#update_overlay(50)\n",
    "def update_overlay(scroll):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    width = df['Image1'][0].shape[1]\n",
    "    scroll_position = int(width * scroll)\n",
    "\n",
    "    # Create the overlay image with scrolling\n",
    "    combined_image = df['Image1'][0].copy()\n",
    "    combined_image[:, scroll_position:] = df['Image2'][0][:, scroll_position:]\n",
    "    \n",
    "    ax.imshow(combined_image, cmap='Reds', interpolation='none')\n",
    "    plt.axis('on')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for scrolling\n",
    "scroll_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.01, description='Scroll:')\n",
    "out = widgets.interactive_output(update_overlay, {'scroll': scroll_slider})\n",
    "#out = widgets.interactive_output(update_overlay1, {'x_pos': scroll_slider})\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "display(scroll_slider, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c47114bb544a50a895c3daa4a8c71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Scroll:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a406aaf51a646a79493af53ffa353e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Generate sample images for the DataFrame\n",
    "image1 = np.random.rand(100, 100)  # Base image\n",
    "image2 = np.random.rand(100, 100)  # Overlay image\n",
    "\n",
    "# Create a DataFrame to store the images\n",
    "df = pd.DataFrame({\n",
    "    'Image1': [image1],\n",
    "    'Image2': [image2]\n",
    "})\n",
    "\n",
    "def update_overlay(scroll):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    width = df['Image1'][0].shape[1]\n",
    "    scroll_position = int(width * scroll)\n",
    "\n",
    "    # Create the combined image with scrolling\n",
    "    combined_image = np.stack((df['Image1'][0],) * 3, axis=-1)  # Convert grayscale to RGB\n",
    "    combined_image[:, scroll_position:, 0] = df['Image2'][0][:, scroll_position:]  # Red channel\n",
    "    combined_image[:, scroll_position:, 1] = 0  # Green channel\n",
    "    combined_image[:, scroll_position:, 2] = 0  # Blue channel\n",
    "    \n",
    "    ax.imshow(combined_image, interpolation='none')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for scrolling\n",
    "scroll_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.01, description='Scroll:')\n",
    "out = widgets.interactive_output(update_overlay, {'scroll': scroll_slider})\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "display(scroll_slider, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c7d756eb1247c79bcf5161aad383f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Scroll:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c76b2a2aa664305b45a6e0932ae8bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Generate sample RGB images for the DataFrame\n",
    "image1 = np.random.rand(100, 100, 3)  # Base image (RGB)\n",
    "image2 = np.random.rand(100, 100, 3)  # Overlay image (RGB)\n",
    "\n",
    "# Create a DataFrame to store the images\n",
    "df = pd.DataFrame({\n",
    "    'Image1': [image1],\n",
    "    'Image2': [image2]\n",
    "})\n",
    "\n",
    "def update_overlay(scroll):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    width = df['Image1'][0].shape[1]\n",
    "    scroll_position = int(width * scroll)\n",
    "\n",
    "    # Create the combined image with scrolling\n",
    "    combined_image = df['Image1'][0].copy()\n",
    "    combined_image[:, scroll_position:] = df['Image2'][0][:, scroll_position:]\n",
    "    \n",
    "    ax.imshow(combined_image, interpolation='none')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for scrolling\n",
    "scroll_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.01, description='Scroll:')\n",
    "out = widgets.interactive_output(update_overlay, {'scroll': scroll_slider})\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "display(scroll_slider, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691ed8bef41c43f692ececde36169c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Scroll:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0668ea5a08145c99476ed321f47cbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def create_image_with_features(seed, num_features=5):\n",
    "    np.random.seed(seed)\n",
    "    image = np.ones((100, 100, 3))  # Initialize a white image\n",
    "    \n",
    "    for _ in range(num_features):\n",
    "        x, y = np.random.randint(0, 100, 2)  # Random position\n",
    "        radius = np.random.randint(5, 15)  # Random radius\n",
    "        color = np.random.rand(3)  # Random color\n",
    "        yy, xx = np.ogrid[:100, :100]\n",
    "        mask = (xx - x) ** 2 + (yy - y) ** 2 <= radius ** 2\n",
    "        image[mask] = color  # Draw the feature\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Create images with features for different time points\n",
    "image1 = create_image_with_features(seed=0)  # Base image (time point 1)\n",
    "image2 = create_image_with_features(seed=1)  # Overlay image (time point 2)\n",
    "\n",
    "# Create a DataFrame to store the images\n",
    "df = pd.DataFrame({\n",
    "    'Image1': [image1],\n",
    "    'Image2': [image2]\n",
    "})\n",
    "\n",
    "def update_overlay(scroll):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    width = df['Image1'][0].shape[1]\n",
    "    scroll_position = int(width * scroll)\n",
    "\n",
    "    # Create the combined image with scrolling\n",
    "    combined_image = df['Image1'][0].copy()\n",
    "    combined_image[:, scroll_position:] = df['Image2'][0][:, scroll_position:]\n",
    "    \n",
    "    ax.imshow(combined_image, interpolation='none')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for scrolling\n",
    "scroll_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.01, description='Scroll:')\n",
    "out = widgets.interactive_output(update_overlay, {'scroll': scroll_slider})\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "display(scroll_slider, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd677b619f049559c8fe47820c38826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Scroll:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df526b8d16c649c68a9b5e066783f733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Generate sample images for the DataFrame\n",
    "image1 = np.random.rand(100, 100)  # Base image\n",
    "image2 = np.random.rand(100, 100)  # Overlay image\n",
    "\n",
    "# Create a DataFrame to store the images\n",
    "df = pd.DataFrame({\n",
    "    'Image1': [image1],\n",
    "    'Image2': [image2]\n",
    "})\n",
    "\n",
    "def update_overlay(scroll):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    width = df['Image1'][0].shape[1]\n",
    "    scroll_position = int(width * scroll)\n",
    "\n",
    "    # Create the overlay image with scrolling\n",
    "    combined_image = df['Image1'][0].copy()\n",
    "    combined_image[:, scroll_position:] = df['Image2'][0][:, scroll_position:]\n",
    "    \n",
    "    ax.imshow(combined_image, cmap='gray', interpolation='none')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for scrolling\n",
    "scroll_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.01, description='Scroll:')\n",
    "out = widgets.interactive_output(update_overlay, {'scroll': scroll_slider})\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "display(scroll_slider, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b46a4743e194ead992839c76328ce06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='Scroll:', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e6b9df8c97437495cec811cb4d316a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def create_synthetic_ndvi(seed):\n",
    "    np.random.seed(seed)\n",
    "    red = np.random.rand(100, 100)\n",
    "    nir = np.random.rand(100, 100)\n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "    return ndvi\n",
    "\n",
    "# Create NDVI images for different time points\n",
    "ndvi1 = create_synthetic_ndvi(seed=0)  # Base NDVI image (time point 1)\n",
    "ndvi2 = create_synthetic_ndvi(seed=1)  # Overlay NDVI image (time point 2)\n",
    "\n",
    "# Normalize NDVI to 0-1 range for visualization\n",
    "ndvi1_normalized = (ndvi1 - np.min(ndvi1)) / (np.max(ndvi1) - np.min(ndvi1))\n",
    "ndvi2_normalized = (ndvi2 - np.min(ndvi2)) / (np.max(ndvi2) - np.min(ndvi2))\n",
    "\n",
    "# Create a DataFrame to store the NDVI images\n",
    "df = pd.DataFrame({\n",
    "    'NDVI1': [ndvi1_normalized],\n",
    "    'NDVI2': [ndvi2_normalized]\n",
    "})\n",
    "\n",
    "def update_overlay(scroll):\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    width = df['NDVI1'][0].shape[1]\n",
    "    scroll_position = int(width * scroll)\n",
    "\n",
    "    # Create the combined image with scrolling\n",
    "    combined_image = np.zeros((100, 100, 3))\n",
    "    combined_image[:, :scroll_position, 1] = df['NDVI1'][0][:, :scroll_position]  # Green for NDVI1\n",
    "    combined_image[:, scroll_position:, 1] = df['NDVI2'][0][:, scroll_position:]  # Green for NDVI2\n",
    "    combined_image[:, scroll_position:, 0] = df['NDVI2'][0][:, scroll_position:]  # Red for NDVI2\n",
    "    \n",
    "    ax.imshow(combined_image, interpolation='none')\n",
    "    plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "# Create a slider widget for scrolling\n",
    "scroll_slider = widgets.FloatSlider(value=0, min=0, max=1, step=0.01, description='Scroll:')\n",
    "out = widgets.interactive_output(update_overlay, {'scroll': scroll_slider})\n",
    "\n",
    "# Display the slider and the initial plot\n",
    "display(scroll_slider, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentinelHubRequest.__init__() missing 2 required positional arguments: 'input_data' and 'responses'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m collection \u001b[38;5;241m=\u001b[39m DataCollection\u001b[38;5;241m.\u001b[39mSENTINEL2_L2A\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Set up Sentinel Hub request\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m request \u001b[38;5;241m=\u001b[39m SentinelHubRequest(\n\u001b[0;32m     23\u001b[0m     data_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Folder to save the downloaded data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional custom evalscript\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m     26\u001b[0m     time\u001b[38;5;241m=\u001b[39mtime_interval,\n\u001b[0;32m     27\u001b[0m     data_collection\u001b[38;5;241m=\u001b[39mcollection,\n\u001b[0;32m     28\u001b[0m     resolution\u001b[38;5;241m=\u001b[39mresolution,\n\u001b[0;32m     29\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional configuration instance\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     maxcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Maximum cloud coverage (adjust as needed)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     instance_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Your Sentinel Hub instance ID\u001b[39;00m\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Perform the request and download the data\u001b[39;00m\n\u001b[0;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget_data(save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: SentinelHubRequest.__init__() missing 2 required positional arguments: 'input_data' and 'responses'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sentinelhub import BBox, CRS, DataCollection, SentinelHubRequest, MimeType\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "tas_bbox = [-110, 53, -110.05, 53.05]  # Coordinates of the area of interest in EPSG:4327\n",
    "# Define the bounding box (BBox) for the area of interest\n",
    "#bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "\n",
    "# Define the resolution and date range for Sentinel-2 data\n",
    "resolution = 10  # Choose appropriate resolution (in meters)\n",
    "time_interval = ('2022-01-01', '2022-12-31')  # Specify date range\n",
    "\n",
    "# Specify the data collection\n",
    "collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "# Set up Sentinel Hub request\n",
    "request = SentinelHubRequest(\n",
    "    data_folder='sentinel_data',  # Folder to save the downloaded data\n",
    "    evalscript=None,  # Optional custom evalscript\n",
    "    bbox=bbox,\n",
    "    time=time_interval,\n",
    "    data_collection=collection,\n",
    "    resolution=resolution,\n",
    "    config=None,  # Optional configuration instance\n",
    "    maxcc=0.2,  # Maximum cloud coverage (adjust as needed)\n",
    "    instance_id=None  # Your Sentinel Hub instance ID\n",
    ")\n",
    "\n",
    "# Perform the request and download the data\n",
    "data = request.get_data(save_data=True)\n",
    "\n",
    "# Access the downloaded bands (assuming you're interested in specific bands)\n",
    "# For simplicity, let's assume you're interested in the Red, Green, Blue, NIR bands\n",
    "red_band = data['B04']  # Red band\n",
    "green_band = data['B03']  # Green band\n",
    "blue_band = data['B02']  # Blue band\n",
    "nir_band = data['B08']   # NIR band\n",
    "\n",
    "# Stack bands into an array\n",
    "sentinel_stack = np.stack([red_band, green_band, blue_band, nir_band], axis=0)\n",
    "\n",
    "# Load training data for supervised classification\n",
    "# You need labeled training samples representing different crop types\n",
    "# Format: [pixel_values, class_label], adjust as per your data\n",
    "training_data = np.load('path_to_training_data.npy')\n",
    "\n",
    "# Split training data into features (X) and labels (y)\n",
    "X = training_data[:, :-1]  # Features (spectral values)\n",
    "y = training_data[:, -1]   # Labels (crop type)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop types for the Sentinel-2 image\n",
    "# Reshape Sentinel stack to match the classifier input shape\n",
    "sentinel_reshaped = sentinel_stack.reshape(sentinel_stack.shape[0], -1).T\n",
    "predictions = clf.predict(sentinel_reshaped)\n",
    "\n",
    "# Reshape predictions to match the original image dimensions\n",
    "classified_map = predictions.reshape(red_band.shape)\n",
    "\n",
    "# Evaluate classification accuracy (if ground truth data is available)\n",
    "accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "# Save the classified map\n",
    "with rasterio.open('classified_map.tif', 'w', **src.meta) as dst:\n",
    "    dst.write(classified_map, 1)\n",
    "\n",
    "print(\"Classification accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentinelHubRequest.__init__() missing 1 required positional argument: 'evalscript'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m collection \u001b[38;5;241m=\u001b[39m DataCollection\u001b[38;5;241m.\u001b[39mSENTINEL2_L2A\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Set up Sentinel Hub request\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m request \u001b[38;5;241m=\u001b[39m SentinelHubRequest(\n\u001b[0;32m     21\u001b[0m     input_data\u001b[38;5;241m=\u001b[39m[(collection, MimeType\u001b[38;5;241m.\u001b[39mTIFF)],  \u001b[38;5;66;03m# Specify input data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     responses\u001b[38;5;241m=\u001b[39m[(MimeType\u001b[38;5;241m.\u001b[39mTIFF, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m)],  \u001b[38;5;66;03m# Specify response format and folder\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m     24\u001b[0m     time\u001b[38;5;241m=\u001b[39mtime_interval,\n\u001b[0;32m     25\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional configuration instance\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     maxcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Maximum cloud coverage (adjust as needed)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     instance_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Your Sentinel Hub instance ID\u001b[39;00m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Perform the request and download the data\u001b[39;00m\n\u001b[0;32m     31\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget_data(save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: SentinelHubRequest.__init__() missing 1 required positional argument: 'evalscript'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sentinelhub import BBox, CRS, DataCollection, SentinelHubRequest, MimeType\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the bounding box (BBox) for the area of interest\n",
    "tas_bbox = [-110, 53, -110.05, 53.05]  # Coordinates of the area of interest in EPSG:4327\n",
    "bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "\n",
    "# Define the resolution and date range for Sentinel-2 data\n",
    "resolution = 10  # Choose appropriate resolution (in meters)\n",
    "time_interval = ('2022-01-01', '2022-12-31')  # Specify date range\n",
    "\n",
    "# Specify the data collection\n",
    "collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "# Set up Sentinel Hub request\n",
    "request = SentinelHubRequest(\n",
    "    input_data=[(collection, MimeType.TIFF)],  # Specify input data\n",
    "    responses=[(MimeType.TIFF, 'sentinel_data')],  # Specify response format and folder\n",
    "    bbox=bbox,\n",
    "    time=time_interval,\n",
    "    config=None,  # Optional configuration instance\n",
    "    maxcc=0.2,  # Maximum cloud coverage (adjust as needed)\n",
    "    instance_id=None  # Your Sentinel Hub instance ID\n",
    ")\n",
    "\n",
    "# Perform the request and download the data\n",
    "data = request.get_data(save_data=True)\n",
    "\n",
    "# Access the downloaded bands (assuming you're interested in specific bands)\n",
    "# For simplicity, let's assume you're interested in the Red, Green, Blue, NIR bands\n",
    "red_band = data['SENTINEL2_L2A'][0]  # Red band\n",
    "green_band = data['SENTINEL2_L2A'][1]  # Green band\n",
    "blue_band = data['SENTINEL2_L2A'][2]  # Blue band\n",
    "nir_band = data['SENTINEL2_L2A'][3]   # NIR band\n",
    "\n",
    "# Stack bands into an array\n",
    "sentinel_stack = np.stack([red_band, green_band, blue_band, nir_band], axis=0)\n",
    "\n",
    "# Load training data for supervised classification\n",
    "# You need labeled training samples representing different crop types\n",
    "# Format: [pixel_values, class_label], adjust as per your data\n",
    "training_data = np.load('path_to_training_data.npy')\n",
    "\n",
    "# Split training data into features (X) and labels (y)\n",
    "X = training_data[:, :-1]  # Features (spectral values)\n",
    "y = training_data[:, -1]   # Labels (crop type)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop types for the Sentinel-2 image\n",
    "# Reshape Sentinel stack to match the classifier input shape\n",
    "sentinel_reshaped = sentinel_stack.reshape(sentinel_stack.shape[0], -1).T\n",
    "predictions = clf.predict(sentinel_reshaped)\n",
    "\n",
    "# Reshape predictions to match the original image dimensions\n",
    "classified_map = predictions.reshape(red_band.shape)\n",
    "\n",
    "# Evaluate classification accuracy (if ground truth data is available)\n",
    "accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "# Save the classified map\n",
    "with rasterio.open('classified_map.tif', 'w', **src.meta) as dst:\n",
    "    dst.write(classified_map, 1)\n",
    "\n",
    "print(\"Classification accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'evalscript' should be a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m collection \u001b[38;5;241m=\u001b[39m DataCollection\u001b[38;5;241m.\u001b[39mSENTINEL2_L2A\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Set up Sentinel Hub request\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m request \u001b[38;5;241m=\u001b[39m SentinelHubRequest(\n\u001b[0;32m     21\u001b[0m     data_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Folder to save the downloaded data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional custom evalscript\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     input_data\u001b[38;5;241m=\u001b[39m[(collection, MimeType\u001b[38;5;241m.\u001b[39mTIFF)],  \u001b[38;5;66;03m# Specify input data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     responses\u001b[38;5;241m=\u001b[39m[(MimeType\u001b[38;5;241m.\u001b[39mTIFF, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m)],  \u001b[38;5;66;03m# Specify response format and folder\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m     26\u001b[0m     time\u001b[38;5;241m=\u001b[39mtime_interval,\n\u001b[0;32m     27\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional configuration instance\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     maxcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Maximum cloud coverage (adjust as needed)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     instance_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Your Sentinel Hub instance ID\u001b[39;00m\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Perform the request and download the data\u001b[39;00m\n\u001b[0;32m     33\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget_data(save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentinelhub\\api\\process.py:59\u001b[0m, in \u001b[0;36mSentinelHubRequest.__init__\u001b[1;34m(self, evalscript, input_data, responses, bbox, geometry, size, resolution, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03mFor details of certain parameters check the\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m`Process API reference <https://docs.sentinel-hub.com/api/latest/reference/#operation/process>`_.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m:param config: A custom instance of config class to override parameters from the saved configuration.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evalscript, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalscript\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m parsed_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mfrom_string(responses[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mTAR \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m parsed_mime_type\n",
      "\u001b[1;31mValueError\u001b[0m: 'evalscript' should be a string"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sentinelhub import BBox, CRS, DataCollection, SentinelHubRequest, MimeType\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the bounding box (BBox) for the area of interest\n",
    "tas_bbox = [-110, 53, -110.05, 53.05]  # Coordinates of the area of interest in EPSG:4327\n",
    "bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "\n",
    "# Define the resolution and date range for Sentinel-2 data\n",
    "resolution = 10  # Choose appropriate resolution (in meters)\n",
    "time_interval = ('2022-01-01', '2022-12-31')  # Specify date range\n",
    "\n",
    "# Specify the data collection\n",
    "collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "# Set up Sentinel Hub request\n",
    "request = SentinelHubRequest(\n",
    "    data_folder='sentinel_data',  # Folder to save the downloaded data\n",
    "    evalscript=None,  # Optional custom evalscript\n",
    "    input_data=[(collection, MimeType.TIFF)],  # Specify input data\n",
    "    responses=[(MimeType.TIFF, 'sentinel_data')],  # Specify response format and folder\n",
    "    bbox=bbox,\n",
    "    time=time_interval,\n",
    "    config=None,  # Optional configuration instance\n",
    "    maxcc=0.2,  # Maximum cloud coverage (adjust as needed)\n",
    "    instance_id=None  # Your Sentinel Hub instance ID\n",
    ")\n",
    "\n",
    "# Perform the request and download the data\n",
    "data = request.get_data(save_data=True)\n",
    "\n",
    "# Access the downloaded bands (assuming you're interested in specific bands)\n",
    "# For simplicity, let's assume you're interested in the Red, Green, Blue, NIR bands\n",
    "red_band = data['SENTINEL2_L2A'][0]  # Red band\n",
    "green_band = data['SENTINEL2_L2A'][1]  # Green band\n",
    "blue_band = data['SENTINEL2_L2A'][2]  # Blue band\n",
    "nir_band = data['SENTINEL2_L2A'][3]   # NIR band\n",
    "\n",
    "# Stack bands into an array\n",
    "sentinel_stack = np.stack([red_band, green_band, blue_band, nir_band], axis=0)\n",
    "\n",
    "# Load training data for supervised classification\n",
    "# You need labeled training samples representing different crop types\n",
    "# Format: [pixel_values, class_label], adjust as per your data\n",
    "training_data = np.load('path_to_training_data.npy')\n",
    "\n",
    "# Split training data into features (X) and labels (y)\n",
    "X = training_data[:, :-1]  # Features (spectral values)\n",
    "y = training_data[:, -1]   # Labels (crop type)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop types for the Sentinel-2 image\n",
    "# Reshape Sentinel stack to match the classifier input shape\n",
    "sentinel_reshaped = sentinel_stack.reshape(sentinel_stack.shape[0], -1).T\n",
    "predictions = clf.predict(sentinel_reshaped)\n",
    "\n",
    "# Reshape predictions to match the original image dimensions\n",
    "classified_map = predictions.reshape(red_band.shape)\n",
    "\n",
    "# Evaluate classification accuracy (if ground truth data is available)\n",
    "accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "# Save the classified map\n",
    "with rasterio.open('classified_map.tif', 'w', **src.meta) as dst:\n",
    "    dst.write(classified_map, 1)\n",
    "\n",
    "print(\"Classification accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'evalscript' should be a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m collection \u001b[38;5;241m=\u001b[39m DataCollection\u001b[38;5;241m.\u001b[39mSENTINEL2_L2A\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Set up Sentinel Hub request\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m request \u001b[38;5;241m=\u001b[39m SentinelHubRequest(\n\u001b[0;32m     21\u001b[0m     data_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Folder to save the downloaded data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# No custom evalscript needed\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     input_data\u001b[38;5;241m=\u001b[39m[(collection, MimeType\u001b[38;5;241m.\u001b[39mTIFF)],  \u001b[38;5;66;03m# Specify input data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     responses\u001b[38;5;241m=\u001b[39m[(MimeType\u001b[38;5;241m.\u001b[39mTIFF, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m)],  \u001b[38;5;66;03m# Specify response format and folder\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m     26\u001b[0m     time\u001b[38;5;241m=\u001b[39mtime_interval,\n\u001b[0;32m     27\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional configuration instance\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     maxcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Maximum cloud coverage (adjust as needed)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     instance_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Your Sentinel Hub instance ID\u001b[39;00m\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Perform the request and download the data\u001b[39;00m\n\u001b[0;32m     33\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget_data(save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentinelhub\\api\\process.py:59\u001b[0m, in \u001b[0;36mSentinelHubRequest.__init__\u001b[1;34m(self, evalscript, input_data, responses, bbox, geometry, size, resolution, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03mFor details of certain parameters check the\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m`Process API reference <https://docs.sentinel-hub.com/api/latest/reference/#operation/process>`_.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m:param config: A custom instance of config class to override parameters from the saved configuration.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evalscript, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalscript\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m parsed_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mfrom_string(responses[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mTAR \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m parsed_mime_type\n",
      "\u001b[1;31mValueError\u001b[0m: 'evalscript' should be a string"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sentinelhub import BBox, CRS, DataCollection, SentinelHubRequest, MimeType\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the bounding box (BBox) for the area of interest\n",
    "tas_bbox = [-110, 53, -110.05, 53.05]  # Coordinates of the area of interest in EPSG:4327\n",
    "bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "\n",
    "# Define the resolution and date range for Sentinel-2 data\n",
    "resolution = 10  # Choose appropriate resolution (in meters)\n",
    "time_interval = ('2022-01-01', '2022-12-31')  # Specify date range\n",
    "\n",
    "# Specify the data collection\n",
    "collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "# Set up Sentinel Hub request\n",
    "request = SentinelHubRequest(\n",
    "    data_folder='sentinel_data',  # Folder to save the downloaded data\n",
    "    evalscript=None,  # No custom evalscript needed\n",
    "    input_data=[(collection, MimeType.TIFF)],  # Specify input data\n",
    "    responses=[(MimeType.TIFF, 'sentinel_data')],  # Specify response format and folder\n",
    "    bbox=bbox,\n",
    "    time=time_interval,\n",
    "    config=None,  # Optional configuration instance\n",
    "    maxcc=0.2,  # Maximum cloud coverage (adjust as needed)\n",
    "    instance_id=None  # Your Sentinel Hub instance ID\n",
    ")\n",
    "\n",
    "# Perform the request and download the data\n",
    "data = request.get_data(save_data=True)\n",
    "\n",
    "# Access the downloaded bands (assuming you're interested in specific bands)\n",
    "# For simplicity, let's assume you're interested in the Red, Green, Blue, NIR bands\n",
    "red_band = data['SENTINEL2_L2A'][0]  # Red band\n",
    "green_band = data['SENTINEL2_L2A'][1]  # Green band\n",
    "blue_band = data['SENTINEL2_L2A'][2]  # Blue band\n",
    "nir_band = data['SENTINEL2_L2A'][3]   # NIR band\n",
    "\n",
    "# Stack bands into an array\n",
    "sentinel_stack = np.stack([red_band, green_band, blue_band, nir_band], axis=0)\n",
    "\n",
    "# Load training data for supervised classification\n",
    "# You need labeled training samples representing different crop types\n",
    "# Format: [pixel_values, class_label], adjust as per your data\n",
    "training_data = np.load('path_to_training_data.npy')\n",
    "\n",
    "# Split training data into features (X) and labels (y)\n",
    "X = training_data[:, :-1]  # Features (spectral values)\n",
    "y = training_data[:, -1]   # Labels (crop type)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop types for the Sentinel-2 image\n",
    "# Reshape Sentinel stack to match the classifier input shape\n",
    "sentinel_reshaped = sentinel_stack.reshape(sentinel_stack.shape[0], -1).T\n",
    "predictions = clf.predict(sentinel_reshaped)\n",
    "\n",
    "# Reshape predictions to match the original image dimensions\n",
    "classified_map = predictions.reshape(red_band.shape)\n",
    "\n",
    "# Evaluate classification accuracy (if ground truth data is available)\n",
    "accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "# Save the classified map\n",
    "with rasterio.open('classified_map.tif', 'w', **src.meta) as dst:\n",
    "    dst.write(classified_map, 1)\n",
    "\n",
    "print(\"Classification accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m collection \u001b[38;5;241m=\u001b[39m DataCollection\u001b[38;5;241m.\u001b[39mSENTINEL2_L2A\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Set up Sentinel Hub request\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m request \u001b[38;5;241m=\u001b[39m SentinelHubRequest(\n\u001b[0;32m     21\u001b[0m     data_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Folder to save the downloaded data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# No custom evalscript needed, pass empty string\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     input_data\u001b[38;5;241m=\u001b[39m[(collection, MimeType\u001b[38;5;241m.\u001b[39mTIFF)],  \u001b[38;5;66;03m# Specify input data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     responses\u001b[38;5;241m=\u001b[39m[(MimeType\u001b[38;5;241m.\u001b[39mTIFF, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m)],  \u001b[38;5;66;03m# Specify response format and folder\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m     26\u001b[0m     time\u001b[38;5;241m=\u001b[39mtime_interval,\n\u001b[0;32m     27\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional configuration instance\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     maxcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Maximum cloud coverage (adjust as needed)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     instance_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Your Sentinel Hub instance ID\u001b[39;00m\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Perform the request and download the data\u001b[39;00m\n\u001b[0;32m     33\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget_data(save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentinelhub\\api\\process.py:61\u001b[0m, in \u001b[0;36mSentinelHubRequest.__init__\u001b[1;34m(self, evalscript, input_data, responses, bbox, geometry, size, resolution, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evalscript, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalscript\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m parsed_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mfrom_string(responses[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mTAR \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m parsed_mime_type\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody(\n\u001b[0;32m     65\u001b[0m     request_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds(bbox\u001b[38;5;241m=\u001b[39mbbox, geometry\u001b[38;5;241m=\u001b[39mgeometry),\n\u001b[0;32m     66\u001b[0m     request_data\u001b[38;5;241m=\u001b[39minput_data,\n\u001b[0;32m     67\u001b[0m     request_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(size\u001b[38;5;241m=\u001b[39msize, resolution\u001b[38;5;241m=\u001b[39mresolution, responses\u001b[38;5;241m=\u001b[39mresponses),\n\u001b[0;32m     68\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39mevalscript,\n\u001b[0;32m     69\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sentinelhub import BBox, CRS, DataCollection, SentinelHubRequest, MimeType\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the bounding box (BBox) for the area of interest\n",
    "tas_bbox = [-110, 53, -110.05, 53.05]  # Coordinates of the area of interest in EPSG:4327\n",
    "bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "\n",
    "# Define the resolution and date range for Sentinel-2 data\n",
    "resolution = 10  # Choose appropriate resolution (in meters)\n",
    "time_interval = ('2022-01-01', '2022-12-31')  # Specify date range\n",
    "\n",
    "# Specify the data collection\n",
    "collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "# Set up Sentinel Hub request\n",
    "request = SentinelHubRequest(\n",
    "    data_folder='sentinel_data',  # Folder to save the downloaded data\n",
    "    evalscript=\"\",  # No custom evalscript needed, pass empty string\n",
    "    input_data=[(collection, MimeType.TIFF)],  # Specify input data\n",
    "    responses=[(MimeType.TIFF, 'sentinel_data')],  # Specify response format and folder\n",
    "    bbox=bbox,\n",
    "    time=time_interval,\n",
    "    config=None,  # Optional configuration instance\n",
    "    maxcc=0.2,  # Maximum cloud coverage (adjust as needed)\n",
    "    instance_id=None  # Your Sentinel Hub instance ID\n",
    ")\n",
    "\n",
    "# Perform the request and download the data\n",
    "data = request.get_data(save_data=True)\n",
    "\n",
    "# Access the downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m collection \u001b[38;5;241m=\u001b[39m DataCollection\u001b[38;5;241m.\u001b[39mSENTINEL2_L2A\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Set up Sentinel Hub request\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m request \u001b[38;5;241m=\u001b[39m SentinelHubRequest(\n\u001b[0;32m     21\u001b[0m     data_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Folder to save the downloaded data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# No custom evalscript needed, pass empty string\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     input_data\u001b[38;5;241m=\u001b[39m[(collection, MimeType\u001b[38;5;241m.\u001b[39mTIFF)],  \u001b[38;5;66;03m# Specify input data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     responses\u001b[38;5;241m=\u001b[39m[(MimeType\u001b[38;5;241m.\u001b[39mTIFF,)],  \u001b[38;5;66;03m# Specify response format\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m     26\u001b[0m     time\u001b[38;5;241m=\u001b[39mtime_interval,\n\u001b[0;32m     27\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional configuration instance\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     maxcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Maximum cloud coverage (adjust as needed)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     instance_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Your Sentinel Hub instance ID\u001b[39;00m\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Perform the request and download the data\u001b[39;00m\n\u001b[0;32m     33\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget_data(save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentinelhub\\api\\process.py:61\u001b[0m, in \u001b[0;36mSentinelHubRequest.__init__\u001b[1;34m(self, evalscript, input_data, responses, bbox, geometry, size, resolution, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evalscript, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalscript\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m parsed_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mfrom_string(responses[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mTAR \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m parsed_mime_type\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody(\n\u001b[0;32m     65\u001b[0m     request_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds(bbox\u001b[38;5;241m=\u001b[39mbbox, geometry\u001b[38;5;241m=\u001b[39mgeometry),\n\u001b[0;32m     66\u001b[0m     request_data\u001b[38;5;241m=\u001b[39minput_data,\n\u001b[0;32m     67\u001b[0m     request_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(size\u001b[38;5;241m=\u001b[39msize, resolution\u001b[38;5;241m=\u001b[39mresolution, responses\u001b[38;5;241m=\u001b[39mresponses),\n\u001b[0;32m     68\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39mevalscript,\n\u001b[0;32m     69\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sentinelhub import BBox, CRS, DataCollection, SentinelHubRequest, MimeType\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the bounding box (BBox) for the area of interest\n",
    "tas_bbox = [-110, 53, -110.05, 53.05]  # Coordinates of the area of interest in EPSG:4327\n",
    "bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "\n",
    "# Define the resolution and date range for Sentinel-2 data\n",
    "resolution = 10  # Choose appropriate resolution (in meters)\n",
    "time_interval = ('2022-01-01', '2022-12-31')  # Specify date range\n",
    "\n",
    "# Specify the data collection\n",
    "collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "# Set up Sentinel Hub request\n",
    "request = SentinelHubRequest(\n",
    "    data_folder='sentinel_data',  # Folder to save the downloaded data\n",
    "    evalscript=\"\",  # No custom evalscript needed, pass empty string\n",
    "    input_data=[(collection, MimeType.TIFF)],  # Specify input data\n",
    "    responses=[(MimeType.TIFF,)],  # Specify response format\n",
    "    bbox=bbox,\n",
    "    time=time_interval,\n",
    "    config=None,  # Optional configuration instance\n",
    "    maxcc=0.2,  # Maximum cloud coverage (adjust as needed)\n",
    "    instance_id=None  # Your Sentinel Hub instance ID\n",
    ")\n",
    "\n",
    "# Perform the request and download the data\n",
    "data = request.get_data(save_data=True)\n",
    "\n",
    "# Access the downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m collection \u001b[38;5;241m=\u001b[39m DataCollection\u001b[38;5;241m.\u001b[39mSENTINEL2_L2A\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Set up Sentinel Hub request\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m request \u001b[38;5;241m=\u001b[39m SentinelHubRequest(\n\u001b[0;32m     21\u001b[0m     data_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Folder to save the downloaded data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# No custom evalscript needed, pass empty string\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     input_data\u001b[38;5;241m=\u001b[39m[(collection, MimeType\u001b[38;5;241m.\u001b[39mTIFF)],  \u001b[38;5;66;03m# Specify input data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     responses\u001b[38;5;241m=\u001b[39m[(MimeType\u001b[38;5;241m.\u001b[39mTIFF,)],  \u001b[38;5;66;03m# Specify response format\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m     26\u001b[0m     time\u001b[38;5;241m=\u001b[39mtime_interval,\n\u001b[0;32m     27\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional configuration instance\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     maxcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Maximum cloud coverage (adjust as needed)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     instance_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Your Sentinel Hub instance ID\u001b[39;00m\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Perform the request and download the data\u001b[39;00m\n\u001b[0;32m     33\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget_data(save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentinelhub\\api\\process.py:61\u001b[0m, in \u001b[0;36mSentinelHubRequest.__init__\u001b[1;34m(self, evalscript, input_data, responses, bbox, geometry, size, resolution, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evalscript, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevalscript\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m parsed_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mfrom_string(responses[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mime_type \u001b[38;5;241m=\u001b[39m MimeType\u001b[38;5;241m.\u001b[39mTAR \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m parsed_mime_type\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpayload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody(\n\u001b[0;32m     65\u001b[0m     request_bounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbounds(bbox\u001b[38;5;241m=\u001b[39mbbox, geometry\u001b[38;5;241m=\u001b[39mgeometry),\n\u001b[0;32m     66\u001b[0m     request_data\u001b[38;5;241m=\u001b[39minput_data,\n\u001b[0;32m     67\u001b[0m     request_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(size\u001b[38;5;241m=\u001b[39msize, resolution\u001b[38;5;241m=\u001b[39mresolution, responses\u001b[38;5;241m=\u001b[39mresponses),\n\u001b[0;32m     68\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39mevalscript,\n\u001b[0;32m     69\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sentinelhub import BBox, CRS, DataCollection, SentinelHubRequest, MimeType\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the bounding box (BBox) for the area of interest\n",
    "tas_bbox = [-110, 53, -110.05, 53.05]  # Coordinates of the area of interest in EPSG:4327\n",
    "bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "\n",
    "# Define the resolution and date range for Sentinel-2 data\n",
    "resolution = 10  # Choose appropriate resolution (in meters)\n",
    "time_interval = ('2022-01-01', '2022-12-31')  # Specify date range\n",
    "\n",
    "# Specify the data collection\n",
    "collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "# Set up Sentinel Hub request\n",
    "request = SentinelHubRequest(\n",
    "    data_folder='sentinel_data',  # Folder to save the downloaded data\n",
    "    evalscript=\"\",  # No custom evalscript needed, pass empty string\n",
    "    input_data=[(collection, MimeType.TIFF)],  # Specify input data\n",
    "    responses=[(MimeType.TIFF,)],  # Specify response format\n",
    "    bbox=bbox,\n",
    "    time=time_interval,\n",
    "    config=None,  # Optional configuration instance\n",
    "    maxcc=0.2,  # Maximum cloud coverage (adjust as needed)\n",
    "    instance_id=None  # Your Sentinel Hub instance ID\n",
    ")\n",
    "\n",
    "# Perform the request and download the data\n",
    "data = request.get_data(save_data=True)\n",
    "\n",
    "# Access the downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting sentinelhub\n",
      "  Downloading sentinelhub-3.10.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aenum>=2.1.4 (from sentinelhub)\n",
      "  Downloading aenum-3.1.15-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from sentinelhub) (8.1.7)\n",
      "Collecting dataclasses-json (from sentinelhub)\n",
      "  Downloading dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy<2 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentinelhub) (1.26.4)\n",
      "Collecting oauthlib (from sentinelhub)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pillow>=9.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentinelhub) (10.2.0)\n",
      "Requirement already satisfied: pyproj>=2.2.0 in c:\\users\\essa\\appdata\\roaming\\python\\python311\\site-packages (from sentinelhub) (3.6.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\programdata\\anaconda3\\lib\\site-packages (from sentinelhub) (2.8.2)\n",
      "Collecting requests-oauthlib>=1.0.0 (from sentinelhub)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.27.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentinelhub) (2.31.0)\n",
      "Requirement already satisfied: shapely in c:\\users\\essa\\appdata\\roaming\\python\\python311\\site-packages (from sentinelhub) (2.0.4)\n",
      "Requirement already satisfied: tifffile>=2020.9.30 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentinelhub) (2023.4.12)\n",
      "Collecting tomli (from sentinelhub)\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting tomli-w (from sentinelhub)\n",
      "  Downloading tomli_w-1.0.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentinelhub) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sentinelhub) (4.9.0)\n",
      "Collecting utm (from sentinelhub)\n",
      "  Downloading utm-0.7.0.tar.gz (8.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from pyproj>=2.2.0->sentinelhub) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27.0->sentinelhub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27.0->sentinelhub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.27.0->sentinelhub) (2.0.7)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->sentinelhub) (0.4.6)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->sentinelhub)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json->sentinelhub)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil->sentinelhub) (1.16.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->sentinelhub) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->sentinelhub) (1.0.0)\n",
      "Downloading sentinelhub-3.10.2-py3-none-any.whl (245 kB)\n",
      "   ---------------------------------------- 0.0/245.6 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 71.7/245.6 kB 1.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 133.1/245.6 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 245.6/245.6 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
      "   ---------------------------------------- 0.0/137.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 137.6/137.6 kB 8.0 MB/s eta 0:00:00\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 61.4/151.7 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 151.7/151.7 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Downloading tomli_w-1.0.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Building wheels for collected packages: utm\n",
      "  Building wheel for utm (setup.py): started\n",
      "  Building wheel for utm (setup.py): finished with status 'done'\n",
      "  Created wheel for utm: filename=utm-0.7.0-py3-none-any.whl size=6103 sha256=16b0e9629f692a2ec7aafdb68478665c989eec8f57bf748eaea5293d67a484c1\n",
      "  Stored in directory: c:\\users\\essa\\appdata\\local\\pip\\cache\\wheels\\c9\\30\\59\\0a0f4976bbec8d13eb19b8ae0d691aeb9499463fb2924bf6d8\n",
      "Successfully built utm\n",
      "Installing collected packages: utm, aenum, typing-inspect, tomli-w, tomli, oauthlib, marshmallow, requests-oauthlib, dataclasses-json, sentinelhub\n",
      "Successfully installed aenum-3.1.15 dataclasses-json-0.6.6 marshmallow-3.21.2 oauthlib-3.2.2 requests-oauthlib-2.0.0 sentinelhub-3.10.2 tomli-2.0.1 tomli-w-1.0.0 typing-inspect-0.9.0 utm-0.7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts sentinelhub.aws.exe, sentinelhub.config.exe, sentinelhub.download.exe and sentinelhub.exe are installed in 'C:\\Users\\Essa\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install sentinelhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentinelHubRequest.__init__() missing 2 required positional arguments: 'input_data' and 'responses'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m collection \u001b[38;5;241m=\u001b[39m DataCollection\u001b[38;5;241m.\u001b[39mSENTINEL2_L2A\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Set up Sentinel Hub request\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m request \u001b[38;5;241m=\u001b[39m SentinelHubRequest(\n\u001b[0;32m     22\u001b[0m     data_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentinel_data\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Folder to save the downloaded data\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     evalscript\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional custom evalscript\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[0;32m     25\u001b[0m     time\u001b[38;5;241m=\u001b[39mtime_interval,\n\u001b[0;32m     26\u001b[0m     data_collection\u001b[38;5;241m=\u001b[39mcollection,\n\u001b[0;32m     27\u001b[0m     resolution\u001b[38;5;241m=\u001b[39mresolution,\n\u001b[0;32m     28\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# Optional configuration instance\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     maxcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,  \u001b[38;5;66;03m# Maximum cloud coverage (adjust as needed)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     instance_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Your Sentinel Hub instance ID\u001b[39;00m\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Perform the request and download the data\u001b[39;00m\n\u001b[0;32m     34\u001b[0m data \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mget_data(save_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: SentinelHubRequest.__init__() missing 2 required positional arguments: 'input_data' and 'responses'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "from sentinelhub import BBox, CRS, DataCollection, SentinelHubRequest, MimeType\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define the bounding box (BBox) for the area of interest\n",
    "tas_bbox = [-110, 53, -110.05, 53.05]  # Coordinates of the area of interest in EPSG:4327\n",
    "\n",
    "bbox = BBox(bbox=tas_bbox, crs=CRS.WGS84)\n",
    "\n",
    "# Define the resolution and date range for Sentinel-2 data\n",
    "resolution = 10  # Choose appropriate resolution (in meters)\n",
    "time_interval = ('2022-01-01', '2022-12-31')  # Specify date range\n",
    "\n",
    "# Specify the data collection\n",
    "collection = DataCollection.SENTINEL2_L2A\n",
    "\n",
    "# Set up Sentinel Hub request\n",
    "request = SentinelHubRequest(\n",
    "    data_folder='sentinel_data',  # Folder to save the downloaded data\n",
    "    evalscript=None,  # Optional custom evalscript\n",
    "    bbox=bbox,\n",
    "    time=time_interval,\n",
    "    data_collection=collection,\n",
    "    resolution=resolution,\n",
    "    config=None,  # Optional configuration instance\n",
    "    maxcc=0.2,  # Maximum cloud coverage (adjust as needed)\n",
    "    instance_id=None  # Your Sentinel Hub instance ID\n",
    ")\n",
    "\n",
    "# Perform the request and download the data\n",
    "data = request.get_data(save_data=True)\n",
    "\n",
    "# Access the downloaded bands (assuming you're interested in specific bands)\n",
    "# For simplicity, let's assume you're interested in the Red, Green, Blue, NIR bands\n",
    "red_band = data['B04']  # Red band\n",
    "green_band = data['B03']  # Green band\n",
    "blue_band = data['B02']  # Blue band\n",
    "nir_band = data['B08']   # NIR band\n",
    "\n",
    "# Stack bands into an array\n",
    "sentinel_stack = np.stack([red_band, green_band, blue_band, nir_band], axis=0)\n",
    "\n",
    "# Load training data for supervised classification\n",
    "# You need labeled training samples representing different crop types\n",
    "# Format: [pixel_values, class_label], adjust as per your data\n",
    "training_data = np.load('path_to_training_data.npy')\n",
    "\n",
    "# Split training data into features (X) and labels (y)\n",
    "X = training_data[:, :-1]  # Features (spectral values)\n",
    "y = training_data[:, -1]   # Labels (crop type)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict crop types for the Sentinel-2 image\n",
    "# Reshape Sentinel stack to match the classifier input shape\n",
    "sentinel_reshaped = sentinel_stack.reshape(sentinel_stack.shape[0], -1).T\n",
    "predictions = clf.predict(sentinel_reshaped)\n",
    "\n",
    "# Reshape predictions to match the original image dimensions\n",
    "classified_map = predictions.reshape(red_band.shape)\n",
    "\n",
    "# Evaluate classification accuracy (if ground truth data is available)\n",
    "accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "# Save the classified map\n",
    "with rasterio.open('classified_map.tif', 'w', **src.meta) as dst:\n",
    "    dst.write(classified_map, 1)\n",
    "\n",
    "print(\"Classification accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
